{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quibble-phu/CiRA-CORE-DETECTION-SET-DE-CARTON/blob/main/BOM_TO_CSV_CiRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code แปลง BOM เป็น CSV ที่ใช้ในโปรแกรม CiRA**\n",
        "\n",
        "> วิธีใช้งานดูได้จากสไลด์เลยครับผม"
      ],
      "metadata": {
        "id": "RFxm-zcGhAbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# กำหนด path\n",
        "path_bom = \"/content/All.csv\"\n",
        "path_subpart = \"/content/Subpart.csv\"\n",
        "path_ignore = \"/content/Ignore.csv\"\n",
        "path_Name =\"/content/NAME.csv\"\n",
        "MyStation = \"100L04\"\n",
        "# โหลด BOM\n",
        "bom_df = pd.read_csv(path_bom)  # ชื่อไฟล์ BOM\n",
        "\n",
        "# โหลด Mapping Table (ไว้แตก part)\n",
        "map_df = pd.read_csv(path_subpart)  # มี Original_Part, Sub_Part, Sub_Qty\n",
        "\n",
        "# โหลด ignore list (Part ที่ไม่ต้องตรวจ)\n",
        "ignore_df = pd.read_csv(path_ignore)  # มีคอลัมน์ชื่อ \"Ignore_Part\"\n",
        "\n",
        "# โหลด model name lookup table\n",
        "model_lookup_df = pd.read_csv(path_Name)  # มี MODEL_CODE, MODEL_NAME\n",
        "# กรองเฉพาะ Station ที่ต้องการ\n",
        "bom_df = bom_df[bom_df[\"STATION_NO\"] == MyStation]\n",
        "# ทำความสะอาดชื่อ part ทั้งหมด\n",
        "bom_df[\"ITEM_DESCRIPTION\"] = bom_df[\"ITEM_DESCRIPTION\"].str.strip().str.lower()\n",
        "bom_df[\"ITEM_NUMBER\"] = bom_df[\"ITEM_NUMBER\"].str.strip()#.str.lower()\n",
        "map_df[\"Original_Part\"] = map_df[\"Original_Part\"].str.strip()#.str.lower()\n",
        "ignore_df[\"Ignore_Part\"] = ignore_df[\"Ignore_Part\"].str.strip()#.str.lower()\n",
        "\n",
        "# เอา BOM ที่ไม่อยู่ใน ignore list เท่านั้น\n",
        "bom_df = bom_df[~bom_df[\"ITEM_NUMBER\"].isin(ignore_df[\"Ignore_Part\"])]\n",
        "\n",
        "# เติม MODEL_NAME จาก lookup table\n",
        "bom_df = bom_df.merge(model_lookup_df, how=\"left\", on=\"MODEL_CODE\")\n",
        "\n",
        "# รวม BOM กับ mapping (แยก part ย่อย)\n",
        "merged = bom_df.merge(map_df, how=\"left\", left_on=\"ITEM_NUMBER\", right_on=\"Original_Part\")\n",
        "\n",
        "# ใช้ Sub_Part ถ้ามี, ไม่งั้นใช้ part เดิม\n",
        "merged[\"Final_Part\"] = merged[\"Sub_Part\"].fillna(merged[\"ITEM_NUMBER\"])\n",
        "merged[\"Final_Qty\"] = merged.apply(\n",
        "    lambda row: row[\"Sub_Qty\"] * row[\"PICKING_QTY\"] if pd.notnull(row[\"Sub_Qty\"]) else row[\"PICKING_QTY\"],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# เลือกเฉพาะคอลัมน์สุดท้าย\n",
        "final_df = merged[[\"MODEL_CODE\", \"MODEL_NAME\",\"ITEM_NUMBER\", \"Final_Part\", \"Final_Qty\"]]\n",
        "final_df.columns = [\"Model\", \"MODEL_NAME\", \"ITEM_NUMBER\", \"Part\", \"QtyNeeded\"]\n",
        "\n",
        "# ลบแถวที่ \"MODEL_NAME ว่าง (เช่น \"\", NaN)\n",
        "final_df = final_df[final_df[\"MODEL_NAME\"].fillna(\"\").str.strip() != \"\"]\n",
        "# บันทึกเป็นไฟล์ใหม่\n",
        "final_df.to_csv(\"expanded_bom.csv\", index=False)"
      ],
      "metadata": {
        "id": "bMyjCIQlhAPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "อันนี้แบบ ลบ Pipe_small ออกจาก RT"
      ],
      "metadata": {
        "id": "fn2EKRUcESFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# กำหนด path\n",
        "path_bom = \"/content/All.csv\"\n",
        "path_subpart = \"/content/Subpart.csv\"\n",
        "path_ignore = \"/content/Ignore.csv\"\n",
        "path_Name =\"/content/NAME.csv\"\n",
        "MyStation = \"100L04\"\n",
        "bom_df = pd.read_csv(path_bom)  # ชื่อไฟล์ BOM\n",
        "\n",
        "# โหลด Mapping Table (ไว้แตก part)\n",
        "map_df = pd.read_csv(path_subpart)  # มี Original_Part, Sub_Part, Sub_Qty\n",
        "\n",
        "# โหลด ignore list (Part ที่ไม่ต้องตรวจ)\n",
        "ignore_df = pd.read_csv(path_ignore)  # มีคอลัมน์ชื่อ \"Ignore_Part\"\n",
        "\n",
        "# โหลด model name lookup table\n",
        "model_lookup_df = pd.read_csv(path_Name)  # มี MODEL_CODE, MODEL_NAME\n",
        "# กรองเฉพาะ Station ที่ต้องการ\n",
        "bom_df = bom_df[bom_df[\"STATION_NO\"] == MyStation]\n",
        "# ทำความสะอาดชื่อ part ทั้งหมด\n",
        "bom_df[\"ITEM_DESCRIPTION\"] = bom_df[\"ITEM_DESCRIPTION\"].str.strip().str.lower()\n",
        "bom_df[\"ITEM_NUMBER\"] = bom_df[\"ITEM_NUMBER\"].str.strip()#.str.lower()\n",
        "map_df[\"Original_Part\"] = map_df[\"Original_Part\"].str.strip()#.str.lower()\n",
        "ignore_df[\"Ignore_Part\"] = ignore_df[\"Ignore_Part\"].str.strip()#.str.lower()\n",
        "\n",
        "# เอา BOM ที่ไม่อยู่ใน ignore list เท่านั้น\n",
        "bom_df = bom_df[~bom_df[\"ITEM_NUMBER\"].isin(ignore_df[\"Ignore_Part\"])]\n",
        "\n",
        "# เติม MODEL_NAME จาก lookup table\n",
        "bom_df = bom_df.merge(model_lookup_df, how=\"left\", on=\"MODEL_CODE\")\n",
        "\n",
        "# รวม BOM กับ mapping (แยก part ย่อย)\n",
        "merged = bom_df.merge(map_df, how=\"left\", left_on=\"ITEM_NUMBER\", right_on=\"Original_Part\")\n",
        "# ลบเฉพาะแถวที่ MODEL_NAME มี \"RT\" และ Sub_Part เป็น \"Pipe_small\"\n",
        "merged = merged[~(\n",
        "    (merged[\"Sub_Part\"] == \"Pipe_small\") &\n",
        "    (merged[\"MODEL_NAME\"].fillna(\"\").str.contains(\"RT\"))\n",
        ")]\n",
        "# ใช้ Sub_Part ถ้ามี, ไม่งั้นใช้ part เดิม\n",
        "merged[\"Final_Part\"] = merged[\"Sub_Part\"].fillna(merged[\"ITEM_NUMBER\"])\n",
        "merged[\"Final_Qty\"] = merged.apply(\n",
        "    lambda row: row[\"Sub_Qty\"] * row[\"PICKING_QTY\"] if pd.notnull(row[\"Sub_Qty\"]) else row[\"PICKING_QTY\"],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# เลือกเฉพาะคอลัมน์สุดท้าย\n",
        "final_df = merged[[\"MODEL_CODE\", \"MODEL_NAME\",\"ITEM_NUMBER\", \"Final_Part\", \"Final_Qty\"]]\n",
        "final_df.columns = [\"Model\", \"MODEL_NAME\", \"ITEM_NUMBER\", \"Part\", \"QtyNeeded\"]\n",
        "\n",
        "# ลบแถวที่ \"MODEL_NAME ว่าง (เช่น \"\", NaN)\n",
        "final_df = final_df[final_df[\"MODEL_NAME\"].fillna(\"\").str.strip() != \"\"]\n",
        "\n",
        "# บันทึกเป็นไฟล์ใหม่\n",
        "final_df.to_csv(\"expanded_bom.csv\", index=False)"
      ],
      "metadata": {
        "id": "6d_C1m_9ESVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d500f5bb-7a55-4459-ccb3-0fc92c078a66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Raw_BOM2.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6ce2ec8c3044>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mMyStation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"100L04\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# โหลด BOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbom_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_bom\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ชื่อไฟล์ BOM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# โหลด Mapping Table (ไว้แตก part)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Raw_BOM2.csv'"
          ]
        }
      ]
    }
  ]
}